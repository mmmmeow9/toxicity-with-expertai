# toxicity-with-expert.ai

This is the core code for paper [A Personalized Harmful Information Detection System Based on User Portraits](https://aisel.aisnet.org/amcis2022/sig_odis/sig_odis/16/)

The paper proposes a personalised harmful information detection framework. Due to size limitations, we only provide the expert.ai implementation for the behavioural traits classification component. The BERT classifier can be referenced from [TensorFlow code and pre-trained models for BERT](https://github.com/google-research/bert), and the Perspective API component can be referenced from [Perspective API documentation](https://github.com/conversationai/perspectiveapi).

## Dataset
Dataset is randomly selected from [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## API key and password
API key and password can be obtained from [expert.ai](https://www.expert.ai/)
